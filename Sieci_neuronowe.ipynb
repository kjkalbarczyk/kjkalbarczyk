{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6S2xkXDxJ1T"
      },
      "source": [
        "#import potrzebnych bibliotek\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import numpy as np\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\r\n",
        "from tensorflow.keras import layers\r\n",
        "from keras.datasets import cifar10\r\n",
        "from keras.constraints import maxnorm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os7jWtGvxSw0"
      },
      "source": [
        "#przypisanie zbioru treningowego i testowego do danych z cifar10\r\n",
        "(x_train,y_train), (x_test,y_test)=cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCTkTle4xS3J"
      },
      "source": [
        "#print(x_train.shape)\r\n",
        "#print(y_train.shape)\r\n",
        "#print(x_test.shape)\r\n",
        "#print(y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM3trFScxS6A"
      },
      "source": [
        "#dopasowanie danych wyjściowych do klasyfikacji\r\n",
        "y_train=to_categorical(y_train)\r\n",
        "y_test=to_categorical(y_test)\r\n",
        "#print(y_train.shape)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuXDcedLxS8x"
      },
      "source": [
        "#zamiana danych wejściowych na wartości od 0 do 1\r\n",
        "x_train= x_train/255\r\n",
        "x_test=x_test/255"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-gtnGGgxS_y"
      },
      "source": [
        "#Budowa sieci\r\n",
        "model= Sequential() \r\n",
        "model.add(Conv2D(32,(5,5),activation=\"relu\",input_shape=(32,32,3), padding='same')) #warstwy konwolucyjne, pierwsza liczba to liczba filtrów, druga kernel\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) #wykorzystanie MaxPoolingu\r\n",
        "model.add(Conv2D(64,(3,3),activation=\"relu\", padding='same'))\r\n",
        "model.add(Dropout(0.3)) #30% wartości usuwanych losowo\r\n",
        "model.add(Conv2D(128,(3,3),activation=\"relu\", padding='same'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "model.add(Conv2D(128,(3,3),activation=\"relu\", padding='same'))\r\n",
        "model.add(Dropout(0.4))\r\n",
        "model.add(Conv2D(128,(3,3),activation=\"relu\"))#\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))#\r\n",
        "model.add(Dropout(0.25))#\r\n",
        "model.add(Flatten()) #zmniejszenie wymiarów sieci\r\n",
        "model.add(Dense(250,activation=\"relu\", kernel_constraint=maxnorm(3)))#\r\n",
        "model.add(Dropout(0.3)) #\r\n",
        "model.add(Dense(10,activation=\"softmax\", kernel_constraint=maxnorm(3)))\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6CMcClBJ2Nn"
      },
      "source": [
        "sprawdziłam wszystkie optymalizatory, pomiędzy adam, adamax i nadam była niewielka różnica wyniku (czego można się spodziewać). Pozostałe nie są odpowiednie do takiego modelu. Pozostaję przy adamax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2cGO_2ExTDJ"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adamax\",metrics=[\"accuracy\"])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW7FwX1SxTGO",
        "outputId": "bc4fbe46-f45d-4345-f76f-4cfe5af32429"
      },
      "source": [
        "#trenowanie sieci\r\n",
        "model.fit(x_train, y_train,batch_size=128,epochs=110)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/110\n",
            "391/391 [==============================] - 11s 9ms/step - loss: 1.9662 - accuracy: 0.2571\n",
            "Epoch 2/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.5512 - accuracy: 0.4269\n",
            "Epoch 3/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.4061 - accuracy: 0.4909\n",
            "Epoch 4/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.2840 - accuracy: 0.5387\n",
            "Epoch 5/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.1970 - accuracy: 0.5707\n",
            "Epoch 6/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.1158 - accuracy: 0.6030\n",
            "Epoch 7/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 1.0400 - accuracy: 0.6300\n",
            "Epoch 8/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.9786 - accuracy: 0.6502\n",
            "Epoch 9/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.9397 - accuracy: 0.6667\n",
            "Epoch 10/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.8969 - accuracy: 0.6872\n",
            "Epoch 11/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.8606 - accuracy: 0.7004\n",
            "Epoch 12/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.8161 - accuracy: 0.7132\n",
            "Epoch 13/110\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.7796 - accuracy: 0.7247\n",
            "Epoch 14/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.7446 - accuracy: 0.7380\n",
            "Epoch 15/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.7242 - accuracy: 0.7461\n",
            "Epoch 16/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.6975 - accuracy: 0.7554\n",
            "Epoch 17/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.6823 - accuracy: 0.7630\n",
            "Epoch 18/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.6617 - accuracy: 0.7673\n",
            "Epoch 19/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.6435 - accuracy: 0.7740\n",
            "Epoch 20/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.6222 - accuracy: 0.7824\n",
            "Epoch 21/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.6154 - accuracy: 0.7828\n",
            "Epoch 22/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5824 - accuracy: 0.7963\n",
            "Epoch 23/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5669 - accuracy: 0.8037\n",
            "Epoch 24/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5547 - accuracy: 0.8042\n",
            "Epoch 25/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5338 - accuracy: 0.8124\n",
            "Epoch 26/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5090 - accuracy: 0.8213\n",
            "Epoch 27/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5116 - accuracy: 0.8197\n",
            "Epoch 28/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.5009 - accuracy: 0.8250\n",
            "Epoch 29/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4832 - accuracy: 0.8304\n",
            "Epoch 30/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4697 - accuracy: 0.8353\n",
            "Epoch 31/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4572 - accuracy: 0.8382\n",
            "Epoch 32/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4435 - accuracy: 0.8439\n",
            "Epoch 33/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4428 - accuracy: 0.8449\n",
            "Epoch 34/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4254 - accuracy: 0.8506\n",
            "Epoch 35/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4181 - accuracy: 0.8543\n",
            "Epoch 36/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4038 - accuracy: 0.8561\n",
            "Epoch 37/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.4046 - accuracy: 0.8545\n",
            "Epoch 38/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3910 - accuracy: 0.8615\n",
            "Epoch 39/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3758 - accuracy: 0.8654\n",
            "Epoch 40/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3726 - accuracy: 0.8667\n",
            "Epoch 41/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3688 - accuracy: 0.8688\n",
            "Epoch 42/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3556 - accuracy: 0.8755\n",
            "Epoch 43/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3493 - accuracy: 0.8744\n",
            "Epoch 44/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3476 - accuracy: 0.8753\n",
            "Epoch 45/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3431 - accuracy: 0.8781\n",
            "Epoch 46/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3293 - accuracy: 0.8826\n",
            "Epoch 47/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3282 - accuracy: 0.8823\n",
            "Epoch 48/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3216 - accuracy: 0.8856\n",
            "Epoch 49/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3180 - accuracy: 0.8858\n",
            "Epoch 50/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.3082 - accuracy: 0.8891\n",
            "Epoch 51/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2905 - accuracy: 0.8974\n",
            "Epoch 52/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2979 - accuracy: 0.8963\n",
            "Epoch 53/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2887 - accuracy: 0.8981\n",
            "Epoch 54/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2875 - accuracy: 0.8974\n",
            "Epoch 55/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2847 - accuracy: 0.8966\n",
            "Epoch 56/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2814 - accuracy: 0.9003\n",
            "Epoch 57/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2697 - accuracy: 0.9015\n",
            "Epoch 58/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2690 - accuracy: 0.9014\n",
            "Epoch 59/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2710 - accuracy: 0.9032\n",
            "Epoch 60/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2664 - accuracy: 0.9050\n",
            "Epoch 61/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2615 - accuracy: 0.9062\n",
            "Epoch 62/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2620 - accuracy: 0.9062\n",
            "Epoch 63/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2569 - accuracy: 0.9077\n",
            "Epoch 64/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2479 - accuracy: 0.9117\n",
            "Epoch 65/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2387 - accuracy: 0.9147\n",
            "Epoch 66/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2363 - accuracy: 0.9154\n",
            "Epoch 67/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2439 - accuracy: 0.9105\n",
            "Epoch 68/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2413 - accuracy: 0.9157\n",
            "Epoch 69/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2301 - accuracy: 0.9189\n",
            "Epoch 70/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2268 - accuracy: 0.9171\n",
            "Epoch 71/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2370 - accuracy: 0.9165\n",
            "Epoch 72/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2221 - accuracy: 0.9196\n",
            "Epoch 73/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2195 - accuracy: 0.9203\n",
            "Epoch 74/110\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2150 - accuracy: 0.9226\n",
            "Epoch 75/110\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2168 - accuracy: 0.9231\n",
            "Epoch 76/110\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.2150 - accuracy: 0.9227\n",
            "Epoch 77/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2133 - accuracy: 0.9222\n",
            "Epoch 78/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2071 - accuracy: 0.9260\n",
            "Epoch 79/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2099 - accuracy: 0.9249\n",
            "Epoch 80/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2082 - accuracy: 0.9245\n",
            "Epoch 81/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2031 - accuracy: 0.9285\n",
            "Epoch 82/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1996 - accuracy: 0.9284\n",
            "Epoch 83/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.2000 - accuracy: 0.9279\n",
            "Epoch 84/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1973 - accuracy: 0.9283\n",
            "Epoch 85/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1922 - accuracy: 0.9300\n",
            "Epoch 86/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1958 - accuracy: 0.9286\n",
            "Epoch 87/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1865 - accuracy: 0.9339\n",
            "Epoch 88/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1848 - accuracy: 0.9342\n",
            "Epoch 89/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1886 - accuracy: 0.9319\n",
            "Epoch 90/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1839 - accuracy: 0.9331\n",
            "Epoch 91/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1803 - accuracy: 0.9344\n",
            "Epoch 92/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1872 - accuracy: 0.9333\n",
            "Epoch 93/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1771 - accuracy: 0.9370\n",
            "Epoch 94/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1782 - accuracy: 0.9352\n",
            "Epoch 95/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1765 - accuracy: 0.9370\n",
            "Epoch 96/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1809 - accuracy: 0.9343\n",
            "Epoch 97/110\n",
            "391/391 [==============================] - 4s 10ms/step - loss: 0.1696 - accuracy: 0.9408\n",
            "Epoch 98/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1695 - accuracy: 0.9379\n",
            "Epoch 99/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1763 - accuracy: 0.9368\n",
            "Epoch 100/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1697 - accuracy: 0.9410\n",
            "Epoch 101/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1612 - accuracy: 0.9422\n",
            "Epoch 102/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1633 - accuracy: 0.9411\n",
            "Epoch 103/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1627 - accuracy: 0.9407\n",
            "Epoch 104/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1656 - accuracy: 0.9406\n",
            "Epoch 105/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1592 - accuracy: 0.9440\n",
            "Epoch 106/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1591 - accuracy: 0.9429\n",
            "Epoch 107/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1589 - accuracy: 0.9434\n",
            "Epoch 108/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1680 - accuracy: 0.9400\n",
            "Epoch 109/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1570 - accuracy: 0.9420\n",
            "Epoch 110/110\n",
            "391/391 [==============================] - 4s 9ms/step - loss: 0.1596 - accuracy: 0.9440\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f10225fbb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBbcBe6_xTMU",
        "outputId": "40045d76-777c-482d-c78d-a7a82d63837b"
      },
      "source": [
        "#wynik dla zbioru testowego\r\n",
        "model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 1s 5ms/step - loss: 0.5530 - accuracy: 0.8407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5530125498771667, 0.8406999707221985]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}